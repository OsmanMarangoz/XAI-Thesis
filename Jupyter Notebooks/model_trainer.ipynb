{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "MODEL TRAINER MITTELS TRANSFER LEARNING AUF VGG16\n",
        "\n",
        "Dieses Skript dient dem Training der Bildklassifikationsmodelle.\n",
        "Es nutzt die Methode des Transfer Learnings, bei der ein auf ImageNet vortrainiertes VGG16-Modell\n",
        "als Basis verwendet und an die spezifischen Klassen des neuen Datensatzes angepasst wird.\n",
        "\n",
        "Der Prozess umfasst folgende Schritte:\n",
        "1. Laden des VGG16-Modells mit den vortrainierten ImageNet-Gewichten, wobei der ursprüngliche\n",
        "   Klassifikationskopf entfernt wird.\n",
        "2. Einfrieren der Gewichte der Basis-Layer, um das in ihnen gespeicherte Wissen zu erhalten.\n",
        "3. Hinzufügen neuer, trainierbarer Layer (GlobalAveragePooling, Dense mit Softmax-Aktivierung),\n",
        "   die auf die Anzahl der Klassen im geladenen Datensatz zugeschnitten sind.\n",
        "4. Laden und Vorverarbeiten des geladenen Datensatzes, inklusive Größenanpassung der Bilder,\n",
        "   VGG-spezifischer Normalisierung und One-Hot-Kodierung der Labels.\n",
        "5. Kompilieren und Trainieren des neuen Modells unter Verwendung von Callbacks wie ModelCheckpoint\n",
        "   (zum Speichern des besten Modells) und EarlyStopping (zur Vermeidung von Overfitting).\n",
        "6. Speichern des final trainierten Modells als .h5-Datei.\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "XJ_R0jaFV4_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWbfpuNL1Zxa",
        "outputId": "b2b65274-5947-4bab-93d9-49af550ec50a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Jun 10 16:09:32 2025       \r\n",
            "+-----------------------------------------------------------------------------------------+\r\n",
            "| NVIDIA-SMI 550.144.03             Driver Version: 550.144.03     CUDA Version: 12.4     |\r\n",
            "|-----------------------------------------+------------------------+----------------------+\r\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\r\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\r\n",
            "|                                         |                        |               MIG M. |\r\n",
            "|=========================================+========================+======================|\r\n",
            "|   0  NVIDIA RTX A6000               Off |   00000000:06:10.0 Off |                  Off |\r\n",
            "| 30%   31C    P8              8W /  300W |       2MiB /  49140MiB |      0%      Default |\r\n",
            "|                                         |                        |                  N/A |\r\n",
            "+-----------------------------------------+------------------------+----------------------+\r\n",
            "                                                                                         \r\n",
            "+-----------------------------------------------------------------------------------------+\r\n",
            "| Processes:                                                                              |\r\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\r\n",
            "|        ID   ID                                                               Usage      |\r\n",
            "|=========================================================================================|\r\n",
            "|  No running processes found                                                             |\r\n",
            "+-----------------------------------------------------------------------------------------+\r\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras import models\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "6xzmmf0Lc5ma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "PwgTinAE1cy5"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BFqO6GLXVvcJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU-Speicherwachstum ermöglichen, um Out-of-Memory-Fehler zu vermeiden\n",
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "if physical_devices:\n",
        "    for device in physical_devices:\n",
        "        tf.config.experimental.set_memory_growth(device, True)\n",
        "    print(f\"GPU verfügbar: {len(physical_devices)} Gerät(e)\")\n",
        "else:\n",
        "    print(\"Keine GPU gefunden, verwende CPU\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7bz5WHkefd_",
        "outputId": "fe97621a-574e-4016-b8b8-dc65f5873a6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU verfügbar: 1 Gerät(e)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Transfer learning, der Layer namen müssen angepasst werden sonst exception mit INNvestigate Bibliothek\n",
        "base_vgg_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "base_vgg_model.trainable = False\n",
        "flat_model_input = keras.Input(shape=(224, 224, 3), name=\"my_flat_model_input\")\n",
        "\n",
        "current_tensor = flat_model_input\n",
        "\n",
        "for layer in base_vgg_model.layers:\n",
        "    if isinstance(layer, keras.layers.InputLayer):\n",
        "        # Skip VGG16's original InputLayer, weil 'flat_model_input'\n",
        "        continue\n",
        "\n",
        "    # Connect the current VGG16 layer\n",
        "    # Pass `training=False` if the layer supports it, because base_vgg_model is frozen\n",
        "    # and its layers (like BatchNormalization) should run in inference mode.\n",
        "    if 'training' in layer.call.__code__.co_varnames:\n",
        "        current_tensor = layer(current_tensor, training=False)\n",
        "    else:\n",
        "        current_tensor = layer(current_tensor)\n",
        "\n",
        "x = keras.layers.GlobalAveragePooling2D(name=\"custom_avg_pool\")(current_tensor)\n",
        "predictions = keras.layers.Dense(397, activation='softmax', name=\"custom_predictions\")(x)\n",
        "flat_model = keras.models.Model(inputs=flat_model_input, outputs=predictions, name=\"MyFlatVGGTransferModel\")\n",
        "\n",
        "flat_model.compile(optimizer=Adam(learning_rate=0.0001),\n",
        "                    loss='categorical_crossentropy',\n",
        "                    metrics=['accuracy'])\n",
        "# Daten vorbereiten\n",
        "BATCH_SIZE = 64"
      ],
      "metadata": {
        "id": "YOfRN1FkWlDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ACWPg7Jc35J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01bf62f8-1203-42a2-deba-fc470e12df1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-06-10 22:43:40.479738: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2025-06-10 22:43:40.480134: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2025-06-10 22:43:40.480358: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2025-06-10 22:43:40.565028: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2025-06-10 22:43:40.565288: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2025-06-10 22:43:40.565444: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:236] Using CUDA malloc Async allocator for GPU: 0\n",
            "2025-06-10 22:43:40.565615: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2025-06-10 22:43:40.565783: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46866 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:06:10.0, compute capability: 8.6\n"
          ]
        }
      ],
      "source": [
        "# Load the model definition.\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Füge neue Layer hinzu für Transfer Learning auf Imagenette\n",
        "x = base_model.output\n",
        "x = keras.layers.GlobalAveragePooling2D()(x)  # avg pooling sonst get dense nicht\n",
        "predictions = keras.layers.Dense(101, activation='softmax',name='dense_ouput')(x)  # 10 outputs für Imagenette\n",
        "\n",
        "# Erstelle das finale Modell\n",
        "model = keras.models.Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Friere die vortrainierten Layer ein\n",
        "base_model.trainable = False\n",
        "\n",
        "# Kompiliere das Modell\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.0001),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Daten vorbereiten\n",
        "BATCH_SIZE = 64\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Definiere Pfad zum gespeicherten Modell\n",
        "model_dir = \"/mnt/data/\"  # Passe dies an dein Verzeichnis an\n",
        "model_path = os.path.join(model_dir, 'vgg16_cifar10_70acc.h5')\n",
        "\n",
        "model = models.load_model(model_path)\n",
        "# Load Imagenette dataset full size = full-size-v2, 160px = 160px\n",
        "(ds_train, ds_test), ds_info = tfds.load(\n",
        "    'sun397/tfds',\n",
        "    split=['train', 'test'],\n",
        "    shuffle_files=False,\n",
        "    as_supervised=False,\n",
        "    with_info=True,\n",
        "    data_dir='/mnt/data/datasets'\n",
        ")\n",
        "num_train_examples = ds_info.splits['train'].num_examples\n",
        "print(f\"Number of pictures in the training dataset: {num_train_examples}\")"
      ],
      "metadata": {
        "id": "-8ksK0wndYby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Anzahl der Klassen aus den Metadaten holen\n",
        "NUM_CLASSES = ds_info.features['label'].num_classes\n",
        "IMAGE_SIZE = [224, 224]\n",
        "BATCH_SIZE = 64 # Setze deine gewünschte Batch-Größe\n",
        "\n",
        "# Kombinierte Preprocessing-Funktion\n",
        "def preprocess_data(element):\n",
        "    \"\"\"\n",
        "    Nimmt ein Dictionary als Eingabe, verarbeitet Bild und Label\n",
        "    und gibt sie als Tupel zurück.\n",
        "    \"\"\"\n",
        "    # 1. Extrahiere Bild und Label aus dem Dictionary\n",
        "    image = element['image']\n",
        "    label = element['label']\n",
        "\n",
        "    # 2. Bildverarbeitung für VGG16\n",
        "    image = tf.image.resize(image, IMAGE_SIZE)\n",
        "    image = preprocess_input(image) # Spezifisches VGG16-Preprocessing\n",
        "\n",
        "    # 3. Label als One-Hot-Vektor kodieren\n",
        "    label = tf.one_hot(label, NUM_CLASSES)\n",
        "\n",
        "    return image, label\n",
        "\n",
        "# Wende die kombinierte Funktion auf die Datensätze an\n",
        "print(\"Preprocessing für den Trainingsdatensatz wird gestartet...\")\n",
        "ds_train = ds_train.map(preprocess_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "ds_train = ds_train.shuffle(buffer_size=1000)\n",
        "ds_train = ds_train.batch(BATCH_SIZE)\n",
        "ds_train = ds_train.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "print(\"Preprocessing für den Testdatensatz wird gestartet...\")\n",
        "ds_test = ds_test.map(preprocess_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "ds_test = ds_test.batch(BATCH_SIZE)\n",
        "ds_test = ds_test.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "print(\"\\n abgeschlossen!\")"
      ],
      "metadata": {
        "id": "N87Njht3uMbU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_vgg(image, label):\n",
        "    # Resize to VGG16's expected input size\n",
        "    image = tf.image.resize(image, [224, 224])\n",
        "    # Apply VGG16 preprocessing (convert to float32 + mean subtraction)\n",
        "    image = preprocess_input(image)\n",
        "    return image, label"
      ],
      "metadata": {
        "id": "8O1C2PiCdhPV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Daten vorbereiten\n",
        "# Wende Preprocessing auf beide Datasets an und bereite sie für das Training vor\n",
        "#ds_train = ds_train.take(80000)\n",
        "ds_train = ds_train.map(preprocess_vgg)\n",
        "ds_train = ds_train.shuffle(buffer_size=1000)\n",
        "ds_train = ds_train.batch(BATCH_SIZE)\n",
        "ds_train = ds_train.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "ds_test = ds_test.map(preprocess_vgg)\n",
        "ds_test = ds_test.batch(BATCH_SIZE)\n",
        "ds_test = ds_test.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "def process_labels(image, label):\n",
        "    # One-hot encoding für 10 Klassen\n",
        "    label = tf.one_hot(label, 101)\n",
        "\n",
        "    return image, label\n",
        "\n",
        "ds_train = ds_train.map(process_labels)\n",
        "ds_test = ds_test.map(process_labels)\n"
      ],
      "metadata": {
        "id": "QdgMJlYpdGtF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check ob richtige split\n",
        "train_images_list = []\n",
        "train_labels_list = []\n",
        "# Iterate through the dataset and append batches to the lists\n",
        "for images, labels in tfds.as_numpy(ds_test):\n",
        "    train_images_list.append(images)\n",
        "    train_labels_list.append(labels)\n",
        "\n",
        "# Concatenate the batches into single NumPy arrays\n",
        "train_images = np.concatenate(train_images_list, axis=0)\n",
        "train_labels = np.concatenate(train_labels_list, axis=0)\n",
        "\n",
        "#check ob tensor alle richtig.\n",
        "print(\"Train images shape:\", train_images.shape)  # Should be (N, 224, 224, 3)\n",
        "print(\"Train images dtype:\", train_images.dtype)  # Should be float32\n",
        "print(\"Train labels shape:\", train_labels.shape)  # Should be (N,)\n",
        "print(\"Train labels dtype:\", train_labels.dtype)  # Should be float32"
      ],
      "metadata": {
        "id": "yve1cCOnXKWK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "923a0e68-b4c1-4f04-8ae4-39f0913f67a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train images shape: (21750, 224, 224, 3)\n",
            "Train images dtype: float32\n",
            "Train labels shape: (21750, 397)\n",
            "Train labels dtype: float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 20\n",
        "\n",
        "# Model-Checkpoint zum Speichern des besten Modells\n",
        "checkpoint_path = \"./models/weights/sun397.weights.h5\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_path,\n",
        "    save_weights_only=False,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Early Stopping um Überanpassung zu vermeiden\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    mode='min',\n",
        "    patience=5,\n",
        "    restore_best_weights=False\n",
        ")\n",
        "\n",
        "# Training starten\n",
        "history = flat_model.fit(\n",
        "    ds_train,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=ds_test,\n",
        "    callbacks=[cp_callback, early_stopping]\n",
        ")\n",
        "flat_model = tf.keras.models.load_model(checkpoint_path)"
      ],
      "metadata": {
        "id": "YfIh35hgdNMd",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluieren Sie es auf den Validierungsdaten (ds_test)\n",
        "# Das gibt Ihnen val_loss und val_accuracy\n",
        "val_loss, val_accuracy = model.evaluate(ds_test, verbose=0)\n",
        "\n",
        "# Evaluieren Sie es auf den Trainingsdaten (ds_train)\n",
        "# Das gibt Ihnen loss und accuracy\n",
        "loss, accuracy = model.evaluate(ds_train, verbose=0)\n",
        "\n",
        "print(f\"loss: {loss:.4f} - accuracy: {accuracy:.4f} - val_loss: {val_loss:.4f} - val_accuracy: {val_accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ig7stVLGdizN",
        "outputId": "61829036-010e-4107-a565-aefabe52e8be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "PERFORMANCE DURCH NEUE EVALUIERUNG:\n",
            "loss: 1.2951 - accuracy: 0.6745 - val_loss: 2.1746 - val_accuracy: 0.5514\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "flat_model.save('./models/vgg16_sun397_a79_va58_l761_vl1768.h5')"
      ],
      "metadata": {
        "id": "om0fK8VWW50s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hilfsfunktion für eine confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "cm = confusion_matrix(true_classes, predicted_classes)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel('Predicted labels')\n",
        "plt.ylabel('True labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TvnTjGfAYy3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Hilfsfunktion um nochmal val acc auszurechnen.\n",
        "#manuel iterieren durch ds_test, und batch wise prediction\n",
        "all_predictions = []\n",
        "all_true_labels = []\n",
        "\n",
        "for images, labels in ds_test:\n",
        "    batch_predictions = model.predict(images, verbose=0)\n",
        "    all_predictions.append(batch_predictions)\n",
        "    all_true_labels.append(labels.numpy())\n",
        "    #print(\"shape der ersten predict: \", batch_predictions.shape)\n",
        "    tf1_pred_classes_batch = np.argmax(images, axis=1)\n",
        "    tf1_true_classes_batch = np.argmax(labels, axis=1)\n",
        "    #print(\"Vorhergesagte Klassen (TF1, erster Batch):\", tf1_pred_classes_batch[:5])\n",
        "    #print(\"Wahre Klassen (TF1, erster Batch):\", tf1_true_classes_batch[:5])\n",
        "\n",
        "\n",
        "\n",
        "# vstack = Concatenate\n",
        "all_predictions = np.vstack(all_predictions)\n",
        "all_true_labels = np.vstack(all_true_labels)\n",
        "\n",
        "# argmax return index mit höchstem wert = klasse die predicted wurde\n",
        "pred_classes = np.argmax(all_predictions, axis=1)\n",
        "true_classes = np.argmax(all_true_labels, axis=1)\n",
        "\n",
        "accuracy = np.mean(pred_classes == true_classes)\n",
        "print(f\"Overall accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Print a few examples\n",
        "#for i in range(100):\n",
        "#   print(f\"Sample {i}: True={true_classes[i]}, Pred={pred_classes[i]}\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "JtLV8JcRZsaa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}